{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":249,"status":"ok","timestamp":1716919080143,"user":{"displayName":"Rifat RzN","userId":"09525507238813107663"},"user_tz":240},"id":"fZA3MDkA8xA-","outputId":"7abd8f14-c094-4316-a025-9ebce6530769"},"outputs":[{"name":"stdout","output_type":"stream","text":["drive  sample_data\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1716919080870,"user":{"displayName":"Rifat RzN","userId":"09525507238813107663"},"user_tz":240},"id":"uvQxMALxCCIH","outputId":"1e9fdd2b-b9ae-4275-ffd8-7a99dce442a5"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/llama3-8b-finetune\n"]}],"source":["%cd drive/MyDrive/Colab Notebooks/llama3-8b-finetune"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":278,"status":"ok","timestamp":1716919081147,"user":{"displayName":"Rifat RzN","userId":"09525507238813107663"},"user_tz":240},"id":"Tl3C-WEQCZiC","outputId":"a0c997f7-9479-49ff-8da5-c3cbe8c5e524"},"outputs":[{"name":"stdout","output_type":"stream","text":["huggingface_tokenizers_cache  lora_model      lora_model.zip.zip  models\n","llama3-8b-finetune.ipynb      lora_model.zip  markdowndata.json   outputs\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"mU5gIE7tCbCO"},"outputs":[],"source":["%%capture\n","import torch\n","major_version, minor_version = torch.cuda.get_device_capability()\n","# Must install separately since Colab has torch 2.2.1, which breaks packages\n","!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n","if major_version >= 8:\n","    # Use this for new GPUs like Ampere, Hopper GPUs (RTX 30xx, RTX 40xx, A100, H100, L40)\n","    !pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes\n","else:\n","    # Use this for older GPUs (V100, Tesla T4, RTX 20xx)\n","    !pip install --no-deps xformers trl peft accelerate bitsandbytes\n","pass\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RD_lpLKEVnE1","outputId":"3a377b0a-4cda-40ab-e614-e676320b1a45"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"]}],"source":["from unsloth import FastLanguageModel\n","import torch\n","max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n","dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n","load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n","\n","# More models at https://huggingface.co/unsloth\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n","    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3694,"status":"ok","timestamp":1716919223283,"user":{"displayName":"Rifat RzN","userId":"09525507238813107663"},"user_tz":240},"id":"AAkHMrhjWBbf","outputId":"0a3ee88d-48ff-4d97-c463-ff7e7c3e8f8f"},"outputs":[{"name":"stderr","output_type":"stream","text":["Unsloth 2024.5 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"]}],"source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = 0, # Supports any, but = 0 is optimized\n","    bias = \"none\",    # Supports any, but = \"none\" is optimized\n","    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n","    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n","    random_state = 3407,\n","    use_rslora = False,  # We support rank stabilized LoRA\n","    loftq_config = None, # And LoftQ\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":622,"referenced_widgets":["d7f3e4b4c4574c3b831c6cddaf9fa79f","a1bf3132a0094b9d8e90623cf7c16dc0","d0d4d63da0584ce79a8397a3bd0c9383","3f6d132c50904bb29d5f7a9e12fd8f57","f6f280744428453188f04eea42999f59","17b1e6cf841442628731505d436f88bc","6f49d633db46446da185c5af18680283","a266fe99601c44f3b71dda60264a9ebc","83e33915fd4f49098ffaf6c1649ac92b","c67a9969465146af895af1305d83e3cd","db1f80abb93440bf92bd4a07dcc29a0d","c92d19442f6f44a691988473a52cc57e","0c4d897c2e0447ad90e0557d554b4650","9b88a6405a69460892ccab536b85f05e","2fdf172236e74f57b192839f4cd70935","ed967426b5244783a0f1b115d9e770f0","5c688aa934984b01b9bc7b6929180f83","ad160dbcdb1241eea42a2828469ac905","41361edb884c4c1085210ddfadd5cff2","672cc2d1d7f24b83bc5c7bcb2bbc13fd","95cc6a9f291d4cad9a85a8db21a691e0","5fbbbc206d7d4fe7a410525d07aa0543"]},"executionInfo":{"elapsed":1459,"status":"ok","timestamp":1716919224736,"user":{"displayName":"Rifat RzN","userId":"09525507238813107663"},"user_tz":240},"id":"baAbbo-jWcs6","outputId":"f292c10c-7218-4b4d-c84a-568428fa1b35"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d7f3e4b4c4574c3b831c6cddaf9fa79f","version_major":2,"version_minor":0},"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c92d19442f6f44a691988473a52cc57e","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/30 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Managing patient flow is vital to the effectiveness of any practice. The system provides fast and easily-navigated functionality for searching current charts and documents, as well as for registering new patients. The system allows users to register individuals directly into the EHR by simply adding their demographic and insurance information into the system. Depending on the established processes, registration documents can be provided either before the appointment or during the check-in process, and a patient registrar can then review the submitted documentation, as needed. The system automatically detects potential duplicate records and allows merging by authorized users. Custom configuration of demographic fields and integration with outside vendors is available as an add-on service, if necessary.\n","\n","### Input:\n","What functionalities does the system provide for managing patient flow?\n","\n","### Response:\n","The system provides functionalities for searching current charts and documents, registering new patients, and managing patient registration by adding demographic and insurance information.<|end_of_text|>\n","Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Managing patient flow is vital to the effectiveness of any practice. The system provides fast and easily-navigated functionality for searching current charts and documents, as well as for registering new patients. The system allows users to register individuals directly into the EHR by simply adding their demographic and insurance information into the system. Depending on the established processes, registration documents can be provided either before the appointment or during the check-in process, and a patient registrar can then review the submitted documentation, as needed. The system automatically detects potential duplicate records and allows merging by authorized users. Custom configuration of demographic fields and integration with outside vendors is available as an add-on service, if necessary.\n","\n","### Input:\n","How does the system handle potential duplicate patient records?\n","\n","### Response:\n","The system automatically detects potential duplicate records and allows merging by authorized users.<|end_of_text|>\n","Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Document Management is an essential component of the system. It supports both web-based remote scanning and high-speed scanning for items such as insurance cards or entire charts. WebScan allows front desk staff to scan information directly into a patient's record, at the point of encounter, and is designed to automatically index the scanned document using barcode technology.\n","\n","### Input:\n","What functionalities does the document management system provide?\n","\n","### Response:\n","The document management system provides functionalities like web-based remote scanning, high-speed scanning for various items, and automatic indexing of scanned documents using barcode technology.<|end_of_text|>\n"]}],"source":["alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","{}\"\"\"\n","\n","EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n","\n","def formatting_prompts_func(examples):\n","    contexts = examples[\"context\"]\n","    questions = examples[\"question\"]\n","    answers = examples[\"answer\"]\n","    texts = []\n","    for context, question, answer in zip(contexts, questions, answers):\n","        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n","        text = alpaca_prompt.format(context, question, answer) + EOS_TOKEN\n","        texts.append(text)\n","    return { \"text\" : texts, }\n","\n","from datasets import load_dataset\n","\n","# Load the custom dataset from the JSON file\n","dataset = load_dataset('json', data_files='./markdowndata.json', split='train')\n","dataset = dataset.map(formatting_prompts_func, batched=True)\n","\n","# Print some samples to verify the dataset\n","for i in range(3):\n","    print(dataset[i]['text'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1716919224737,"user":{"displayName":"Rifat RzN","userId":"09525507238813107663"},"user_tz":240},"id":"5gjC8q4eYqxY","outputId":"b749e4f9-66f9-44e2-b337-24a3f87248aa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Managing patient flow is vital to the effectiveness of any practice. The system provides fast and easily-navigated functionality for searching current charts and documents, as well as for registering new patients. The system allows users to register individuals directly into the EHR by simply adding their demographic and insurance information into the system. Depending on the established processes, registration documents can be provided either before the appointment or during the check-in process, and a patient registrar can then review the submitted documentation, as needed. The system automatically detects potential duplicate records and allows merging by authorized users. Custom configuration of demographic fields and integration with outside vendors is available as an add-on service, if necessary.\n","\n","### Input:\n","What functionalities does the system provide for managing patient flow?\n","\n","### Response:\n","The system provides functionalities for searching current charts and documents, registering new patients, and managing patient registration by adding demographic and insurance information.<|end_of_text|>\n","Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Managing patient flow is vital to the effectiveness of any practice. The system provides fast and easily-navigated functionality for searching current charts and documents, as well as for registering new patients. The system allows users to register individuals directly into the EHR by simply adding their demographic and insurance information into the system. Depending on the established processes, registration documents can be provided either before the appointment or during the check-in process, and a patient registrar can then review the submitted documentation, as needed. The system automatically detects potential duplicate records and allows merging by authorized users. Custom configuration of demographic fields and integration with outside vendors is available as an add-on service, if necessary.\n","\n","### Input:\n","How does the system handle potential duplicate patient records?\n","\n","### Response:\n","The system automatically detects potential duplicate records and allows merging by authorized users.<|end_of_text|>\n","Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Document Management is an essential component of the system. It supports both web-based remote scanning and high-speed scanning for items such as insurance cards or entire charts. WebScan allows front desk staff to scan information directly into a patient's record, at the point of encounter, and is designed to automatically index the scanned document using barcode technology.\n","\n","### Input:\n","What functionalities does the document management system provide?\n","\n","### Response:\n","The document management system provides functionalities like web-based remote scanning, high-speed scanning for various items, and automatic indexing of scanned documents using barcode technology.<|end_of_text|>\n"]}],"source":["# Print some samples to verify the dataset\n","for i in range(3):\n","    print(dataset[i]['text'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121,"referenced_widgets":["7a0c835f8b2249b98303628dd1c994f7","938864c07ccb4428a3a34ad696945161","386cece2550347e18d1f30c268d71163","7c6baf44c3534922b9f4afeb147271c6","289bab6c3b72442aaf41ef05bfc335a0","c84a2c763cc34a62bee4e55b2976d37b","79daf67b9b224dcda46d5b1b887f6d31","95c1cd2e84e749e3b158f0a2e34d1861","978dea8a0a244977a10d589b1fda731e","ef32856282da43aeaca34efa9c3e1821","0593291d3ea940cdad8564dd668ca8da"]},"executionInfo":{"elapsed":2139,"status":"ok","timestamp":1716919226865,"user":{"displayName":"Rifat RzN","userId":"09525507238813107663"},"user_tz":240},"id":"mRfVge9QYynM","outputId":"fdbe2e5b-e032-4a4e-de9b-b6831e9937fc"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7a0c835f8b2249b98303628dd1c994f7","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=2):   0%|          | 0/30 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["max_steps is given, it will override any value given in num_train_epochs\n"]}],"source":["from trl import SFTTrainer\n","from transformers import TrainingArguments\n","\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = dataset,\n","    dataset_text_field = \"text\",\n","    max_seq_length = max_seq_length,\n","    dataset_num_proc = 2,\n","    packing = False, # Can make training 5x faster for short sequences.\n","    args = TrainingArguments(\n","        per_device_train_batch_size = 2,\n","        gradient_accumulation_steps = 4,\n","        warmup_steps = 5,\n","        max_steps = 60,\n","        learning_rate = 2e-4,\n","        fp16 = not torch.cuda.is_bf16_supported(),\n","        bf16 = torch.cuda.is_bf16_supported(),\n","        logging_steps = 1,\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.01,\n","        lr_scheduler_type = \"linear\",\n","        seed = 3407,\n","        output_dir = \"outputs\",\n","    ),\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1716919226865,"user":{"displayName":"Rifat RzN","userId":"09525507238813107663"},"user_tz":240},"id":"DyeH2DbVoIbV","outputId":"42ae1f80-6522-4cc6-8390-25da6398922f"},"outputs":[{"name":"stdout","output_type":"stream","text":["GPU = Tesla T4. Max memory = 14.748 GB.\n","5.605 GB of memory reserved.\n"]}],"source":["#@title Show current memory stats\n","gpu_stats = torch.cuda.get_device_properties(0)\n","start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n","print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n","print(f\"{start_gpu_memory} GB of memory reserved.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":433300,"status":"ok","timestamp":1716919660163,"user":{"displayName":"Rifat RzN","userId":"09525507238813107663"},"user_tz":240},"id":"pZtc7BVFoWCv","outputId":"348a5e09-55e0-4625-c573-3e417b43ccc9"},"outputs":[{"name":"stderr","output_type":"stream","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 30 | Num Epochs = 20\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n","\\        /    Total batch size = 8 | Total steps = 60\n"," \"-____-\"     Number of trainable parameters = 41,943,040\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [60/60 06:47, Epoch 16/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.434000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>2.415500</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>2.474900</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>2.423200</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>2.255300</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>1.970700</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>1.792100</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>1.721400</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>1.537900</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>1.316500</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>1.580100</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>1.346400</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>1.323200</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>1.222800</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>1.373000</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>1.227800</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>1.203300</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>1.124700</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>1.069100</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.939800</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>1.038600</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.858500</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.754800</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.672600</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.760600</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.831400</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.679800</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.390400</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.640300</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.485700</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>0.444700</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.326600</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>0.516200</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>0.192700</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>0.336500</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>0.328100</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>0.196700</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>0.209900</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>0.194900</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.240600</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>0.169000</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>0.129400</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>0.076900</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>0.100800</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.223400</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>0.037800</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>0.168700</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>0.061900</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>0.094100</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.042500</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>0.164400</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>0.039300</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>0.042100</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>0.097500</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>0.060700</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>0.034500</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>0.026300</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>0.028400</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>0.051800</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.085100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["trainer_stats = trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1716919660164,"user":{"displayName":"Rifat RzN","userId":"09525507238813107663"},"user_tz":240},"id":"oLrP28YMocHD","outputId":"afa09bcd-6787-46a6-8d3f-8ce4db3317b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["427.3291 seconds used for training.\n","7.12 minutes used for training.\n","Peak reserved memory = 6.996 GB.\n","Peak reserved memory for training = 1.391 GB.\n","Peak reserved memory % of max memory = 47.437 %.\n","Peak reserved memory for training % of max memory = 9.432 %.\n"]}],"source":["#@title Show final memory and time stats\n","used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n","used_percentage = round(used_memory         /max_memory*100, 3)\n","lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n","print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n","print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n","print(f\"Peak reserved memory = {used_memory} GB.\")\n","print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n","print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n","print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2788,"status":"ok","timestamp":1716919662936,"user":{"displayName":"Rifat RzN","userId":"09525507238813107663"},"user_tz":240},"id":"S2hMLGxOrPHs","outputId":"1b9684f5-8c3c-409e-a566-e1ddcb0a8ce9"},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"data":{"text/plain":["['<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nContinue the fibonnaci sequence.\\n\\n### Input:\\n1, 1, 2, 3, 5, 8\\n\\n### Response:\\nThe input continues the Fibonacci sequence with the values 1, 1, 2, 3, 5, and 8.<|end_of_text|>']"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["\n","alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","{}\"\"\"\n","\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        \"Continue the fibonnaci sequence.\", # instruction\n","        \"1, 1, 2, 3, 5, 8\", # input\n","        \"\", # output - leave this blank for generation!\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n","tokenizer.batch_decode(outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2316,"status":"ok","timestamp":1716919665230,"user":{"displayName":"Rifat RzN","userId":"09525507238813107663"},"user_tz":240},"id":"NAXqf6G0rlLL","outputId":"5e1026fe-725a-42bb-a2b3-b23e889184d4"},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Continue the fibonnaci sequence.\n","\n","### Input:\n","1, 1, 2, 3, 5, 8\n","\n","### Response:\n","The input continues the Fibonacci sequence with the values 1, 1, 2, 3, 5, and 8.<|end_of_text|>\n"]}],"source":["\n","alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","{}\"\"\"\n","\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        \"Continue the fibonnaci sequence.\", # instruction\n","        \"1, 1, 2, 3, 5, 8\", # input\n","        \"\", # output - leave this blank for generation!\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","from transformers import TextStreamer\n","text_streamer = TextStreamer(tokenizer)\n","_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":807},"executionInfo":{"elapsed":2955,"status":"error","timestamp":1716922290597,"user":{"displayName":"Rifat RzN","userId":"09525507238813107663"},"user_tz":240},"id":"-eKOnbairurM","outputId":"741fe235-1ec4-46cf-f82b-193af68f0adf"},"outputs":[{"ename":"HfHubHTTPError","evalue":"401 Client Error: Unauthorized for url: https://huggingface.co/api/repos/create (Request ID: Root=1-665627b0-59b7290e1aed4ddc0cf3b780;747f2c31-2e64-4923-8a6a-00d42bd291e0)\n\nInvalid username or password.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/repos/create","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unsloth/save.py\u001b[0m in \u001b[0;36munsloth_push_to_hub\u001b[0;34m(self, repo_id, use_temp_dir, commit_message, private, token, max_shard_size, create_pr, safe_serialization, revision, commit_description, tags, **deprecated_kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mpush_to_hub\u001b[0;34m(self, repo_id, use_temp_dir, commit_message, private, token, max_shard_size, create_pr, safe_serialization, revision, commit_description, tags, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m         repo_id = self._create_repo(\n\u001b[0m\u001b[1;32m    876\u001b[0m             \u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprivate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprivate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morganization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morganization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36m_create_repo\u001b[0;34m(self, repo_id, private, token, repo_url, organization)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_repo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprivate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprivate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mcreate_repo\u001b[0;34m(self, repo_id, token, private, repo_type, exist_ok, space_sdk, space_hardware, space_storage, space_sleep_time, space_secrets, space_variables)\u001b[0m\n\u001b[1;32m   3255\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3256\u001b[0;31m             \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3257\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;31m# as well (request id and/or server error message)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHfHubHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHfHubHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/repos/create (Request ID: Root=1-665627af-6bbbe74164aad92a34b6f57e;89b18c9e-83bd-46c1-a36a-e77f058c9246)\n\nInvalid username or password.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/repos/create","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-01ad813d3c93>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lora_model\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Local saving\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_to_hub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rifatrzn/lora_model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Online saving\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unsloth/save.py\u001b[0m in \u001b[0;36munsloth_push_to_hub\u001b[0;34m(self, repo_id, use_temp_dir, commit_message, private, token, max_shard_size, create_pr, safe_serialization, revision, commit_description, tags, **deprecated_kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mpush_to_hub\u001b[0;34m(self, repo_id, use_temp_dir, commit_message, private, token, max_shard_size, create_pr, safe_serialization, revision, commit_description, tags, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0morganization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeprecated_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"organization\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m         repo_id = self._create_repo(\n\u001b[0m\u001b[1;32m    876\u001b[0m             \u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprivate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprivate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morganization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morganization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36m_create_repo\u001b[0;34m(self, repo_id, private, token, repo_url, organization)\u001b[0m\n\u001b[1;32m    689\u001b[0m                 \u001b[0mrepo_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{organization}/{repo_id}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_repo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprivate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprivate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mcreate_repo\u001b[0;34m(self, repo_id, token, private, repo_type, exist_ok, space_sdk, space_hardware, space_storage, space_sleep_time, space_secrets, space_variables)\u001b[0m\n\u001b[1;32m   3254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3255\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3256\u001b[0;31m             \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3257\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3258\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mexist_ok\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m409\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;31m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;31m# as well (request id and/or server error message)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHfHubHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHfHubHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/repos/create (Request ID: Root=1-665627b0-59b7290e1aed4ddc0cf3b780;747f2c31-2e64-4923-8a6a-00d42bd291e0)\n\nInvalid username or password."]}],"source":["model.save_pretrained(\"lora_model\") # Local saving\n","# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4188,"status":"ok","timestamp":1716919687937,"user":{"displayName":"Rifat RzN","userId":"09525507238813107663"},"user_tz":240},"id":"ztkClsK-se5B","outputId":"267db1b4-6afd-4598-b4cf-5c6e7e2ba19f"},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"data":{"text/plain":["['<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nThe {{% system-name %}} Tasking module streamlines everyday tasks into an electronic to-do list, and provides a single, structured point of access to routine work activities. The module allows clinicians to review lab results, authorize prescriptions and orders, and e-sign encounters or dictation.\\n\\n### Input:\\nWhat functionalities does the Tasking module provide?\\n\\n### Response:\\nThe Tasking module streamlines everyday tasks into an electronic to-do list and provides a single, structured point of access to routine work activities. It allows clinicians to review lab results, authorize prescriptions and orders, and e-sign encounters or dictation.<|end_of_text|>']"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["if False:\n","    from unsloth import FastLanguageModel\n","    model, tokenizer = FastLanguageModel.from_pretrained(\n","        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n","        max_seq_length = max_seq_length,\n","        dtype = dtype,\n","        load_in_4bit = load_in_4bit,\n","    )\n","    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","\n","alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","{}\"\"\"\n","\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        \"The {{% system-name %}} Tasking module streamlines everyday tasks into an electronic to-do list, and provides a single, structured point of access to routine work activities. The module allows clinicians to review lab results, authorize prescriptions and orders, and e-sign encounters or dictation.\", # instruction\n","        \"What functionalities does the Tasking module provide?\", # input\n","        \"\", # output - leave this blank for generation!\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n","tokenizer.batch_decode(outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11355,"status":"ok","timestamp":1716922064743,"user":{"displayName":"Rifat RzN","userId":"09525507238813107663"},"user_tz":240},"id":"N_RsfbZoh1F7","outputId":"43509a35-da4b-48d5-e010-b93a893394be"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n","    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","Enter your token (input will not be visible): \n","Add token as git credential? (Y/n) y\n","Token is valid (permission: write).\n","\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n","You might have to re-authenticate when pushing to the Hugging Face Hub.\n","Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n","\n","git config --global credential.helper store\n","\n","Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n","Token has not been saved to git credential helper.\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["!huggingface-cli login"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hsuxClxLs_pQ"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kzp3HxuPdc4K"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15931,"status":"ok","timestamp":1716923509856,"user":{"displayName":"Rifat RzN","userId":"09525507238813107663"},"user_tz":240},"id":"RGOjqCWPgwXq","outputId":"de56df98-2515-4f01-c3bf-831cfb61b6b3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Saved model to https://huggingface.co/rifatrzn/questionnaire-llama3-finetune\n"]}],"source":["model.save_pretrained(\"lora_model\") # Local saving\n","model.push_to_hub(\"rifatrzn/questionnaire-llama3-finetune\", token = \"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\") # Online saving"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KKPAmdmjjCwP"},"outputs":[],"source":["# Merge to 16bit\n","if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n","if False: model.push_to_hub_merged(\"rifatrzn/questionnaire-llama3-finetune\", tokenizer, save_method = \"merged_16bit\", token = \"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\")\n","\n","# Merge to 4bit\n","if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n","if False: model.push_to_hub_merged(\"rifatrzn/questionnaire-llama3-finetune\", tokenizer, save_method = \"merged_4bit\", token = \"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\")\n","\n","# Just LoRA adapters\n","if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n","if False: model.push_to_hub_merged(\"rifatrzn/questionnaire-llama3-finetune\", tokenizer, save_method = \"lora\", token = \"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\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3WuKqwD7kQjC"},"outputs":[],"source":["# Save to 8bit Q8_0\n","if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n","if False: model.push_to_hub_gguf(\"rifatrzn/questionnaire-llama3-finetune\", tokenizer, token = \"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\")\n","\n","# Save to 16bit GGUF\n","if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n","if False: model.push_to_hub_gguf(\"rifatrzn/questionnaire-llama3-finetune\", tokenizer, quantization_method = \"f16\", token = \"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\")\n","\n","# Save to q4_k_m GGUF\n","if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n","if False: model.push_to_hub_gguf(\"rifatrzn/questionnaire-llama3-finetune\", tokenizer, quantization_method = \"q4_k_m\", token = \"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\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":249,"status":"ok","timestamp":1716924708453,"user":{"displayName":"Rifat RzN","userId":"09525507238813107663"},"user_tz":240},"id":"Ss_p4jr5ru8t","outputId":"39fdab9a-64dd-414f-8a05-a3755acf64a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/llama3-8b-finetune\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12109,"status":"ok","timestamp":1716925375634,"user":{"displayName":"Rifat RzN","userId":"09525507238813107663"},"user_tz":240},"id":"DQ8z-4uRr_DE","outputId":"0408345d-7bc8-4284-be2f-7082ffff5608"},"outputs":[{"name":"stdout","output_type":"stream","text":["  adding: lora_model/ (stored 0%)\n","  adding: lora_model/README.md (deflated 66%)\n","  adding: lora_model/adapter_model.safetensors (deflated 7%)\n","  adding: lora_model/adapter_config.json (deflated 54%)\n","  adding: lora_model/tokenizer_config.json (deflated 96%)\n","  adding: lora_model/special_tokens_map.json (deflated 71%)\n","  adding: lora_model/tokenizer.json (deflated 74%)\n"]}],"source":["!zip -r lora_model.zip lora_model/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"executionInfo":{"elapsed":0,"status":"error","timestamp":1716935252649,"user":{"displayName":"Rifat RzN","userId":"09525507238813107663"},"user_tz":240},"id":"G3LZt2e-tqJs","outputId":"3cdc682b-6d3f-4439-9e35-7bd023405a5b"},"outputs":[{"ename":"FileNotFoundError","evalue":"Cannot find file: lora_model.zip","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-ee54bc2b585e>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Download the zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lora_model.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    223\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find file: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: lora_model.zip"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":246,"status":"ok","timestamp":1716925354383,"user":{"displayName":"Rifat RzN","userId":"09525507238813107663"},"user_tz":240},"id":"MpJ-eGaysLvM","outputId":"eb9765a7-72ea-499d-b053-7103e6d4eeed"},"outputs":[{"data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":["download(\"download_719c75df-de5e-4225-9a4e-50f512b8496a\", \"lora_model.zip\", 22)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vjW1pOQ6sfzp"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"mount_file_id":"1qi-_eaEQxkJObFQTAXT4X_gl5W_Iwq-3","authorship_tag":"ABX9TyOTdYsE3dBvOrJoGWxIae+Z"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0593291d3ea940cdad8564dd668ca8da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c4d897c2e0447ad90e0557d554b4650":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c688aa934984b01b9bc7b6929180f83","placeholder":"â€‹","style":"IPY_MODEL_ad160dbcdb1241eea42a2828469ac905","value":"Map:â€‡100%"}},"17b1e6cf841442628731505d436f88bc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"289bab6c3b72442aaf41ef05bfc335a0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fdf172236e74f57b192839f4cd70935":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95cc6a9f291d4cad9a85a8db21a691e0","placeholder":"â€‹","style":"IPY_MODEL_5fbbbc206d7d4fe7a410525d07aa0543","value":"â€‡30/30â€‡[00:00&lt;00:00,â€‡986.36â€‡examples/s]"}},"386cece2550347e18d1f30c268d71163":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_95c1cd2e84e749e3b158f0a2e34d1861","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_978dea8a0a244977a10d589b1fda731e","value":30}},"3f6d132c50904bb29d5f7a9e12fd8f57":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c67a9969465146af895af1305d83e3cd","placeholder":"â€‹","style":"IPY_MODEL_db1f80abb93440bf92bd4a07dcc29a0d","value":"â€‡30/0â€‡[00:00&lt;00:00,â€‡564.68â€‡examples/s]"}},"41361edb884c4c1085210ddfadd5cff2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c688aa934984b01b9bc7b6929180f83":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fbbbc206d7d4fe7a410525d07aa0543":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"672cc2d1d7f24b83bc5c7bcb2bbc13fd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6f49d633db46446da185c5af18680283":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"79daf67b9b224dcda46d5b1b887f6d31":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a0c835f8b2249b98303628dd1c994f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_938864c07ccb4428a3a34ad696945161","IPY_MODEL_386cece2550347e18d1f30c268d71163","IPY_MODEL_7c6baf44c3534922b9f4afeb147271c6"],"layout":"IPY_MODEL_289bab6c3b72442aaf41ef05bfc335a0"}},"7c6baf44c3534922b9f4afeb147271c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef32856282da43aeaca34efa9c3e1821","placeholder":"â€‹","style":"IPY_MODEL_0593291d3ea940cdad8564dd668ca8da","value":"â€‡30/30â€‡[00:01&lt;00:00,â€‡18.95â€‡examples/s]"}},"83e33915fd4f49098ffaf6c1649ac92b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"938864c07ccb4428a3a34ad696945161":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c84a2c763cc34a62bee4e55b2976d37b","placeholder":"â€‹","style":"IPY_MODEL_79daf67b9b224dcda46d5b1b887f6d31","value":"Mapâ€‡(num_proc=2):â€‡100%"}},"95c1cd2e84e749e3b158f0a2e34d1861":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95cc6a9f291d4cad9a85a8db21a691e0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"978dea8a0a244977a10d589b1fda731e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9b88a6405a69460892ccab536b85f05e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_41361edb884c4c1085210ddfadd5cff2","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_672cc2d1d7f24b83bc5c7bcb2bbc13fd","value":30}},"a1bf3132a0094b9d8e90623cf7c16dc0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17b1e6cf841442628731505d436f88bc","placeholder":"â€‹","style":"IPY_MODEL_6f49d633db46446da185c5af18680283","value":"Generatingâ€‡trainâ€‡split:â€‡"}},"a266fe99601c44f3b71dda60264a9ebc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"ad160dbcdb1241eea42a2828469ac905":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c67a9969465146af895af1305d83e3cd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c84a2c763cc34a62bee4e55b2976d37b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c92d19442f6f44a691988473a52cc57e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0c4d897c2e0447ad90e0557d554b4650","IPY_MODEL_9b88a6405a69460892ccab536b85f05e","IPY_MODEL_2fdf172236e74f57b192839f4cd70935"],"layout":"IPY_MODEL_ed967426b5244783a0f1b115d9e770f0"}},"d0d4d63da0584ce79a8397a3bd0c9383":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a266fe99601c44f3b71dda60264a9ebc","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_83e33915fd4f49098ffaf6c1649ac92b","value":1}},"d7f3e4b4c4574c3b831c6cddaf9fa79f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a1bf3132a0094b9d8e90623cf7c16dc0","IPY_MODEL_d0d4d63da0584ce79a8397a3bd0c9383","IPY_MODEL_3f6d132c50904bb29d5f7a9e12fd8f57"],"layout":"IPY_MODEL_f6f280744428453188f04eea42999f59"}},"db1f80abb93440bf92bd4a07dcc29a0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed967426b5244783a0f1b115d9e770f0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef32856282da43aeaca34efa9c3e1821":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6f280744428453188f04eea42999f59":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}